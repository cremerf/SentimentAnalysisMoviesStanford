{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Large Movie Review Dataset\n",
    "\n",
    "Hi again! You will be expected to finish this on your own, but you can use the available channels on Discord to ask questions and help others. Please read the entire notebook before starting, this will give you a better idea of what you need to accomplish.\n",
    "\n",
    "This project is related to NLP. As you may already know, the most important and hardest part of an NLP project is pre-processing, which is why we are going to focus on that.\n",
    "\n",
    "Regarding the data, we are not going to have a __csv file__, that would be too easy :) instead we are going to download the data from [AI Stanford Dataset](https://ai.stanford.edu/~amaas/data/sentiment/). When you download them you will notice that their format is text files, so you will have to work a little there to be able to use and process them. This is a dataset for __binary sentiment classification__.\n",
    "\n",
    "Basically a basic sentiment analysis problem, as in this case, consists of a classification problem, where the possible output labels are: `positive` and `negative`. Which indicates, if the review of a movie speaks positively or negatively. In our case it is a binary problem, but one could have many more \"feelings\" tagged and thus allow a more granular analysis.\n",
    "\n",
    "### These are the objectives of the project:\n",
    "\n",
    "* Read data that is not in a traditional format.\n",
    "* Put together a set of preprocessing functions that we can use later on any NLP or related problems.\n",
    "* Vectorize the data in order to apply a machine learning model to it: using BoW or TF-IDF.\n",
    "* BoW and TF-IDF are classic ways to vectorize text, but currently we have some more complex ways with better performance, for this we are going to train our own word embedding and use it as a vectorization source for our data.\n",
    "* Train a sentiment analysis model that allows us to detect positive and negative opinions in movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "response = urllib.request.urlopen('https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz')\n",
    "html = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "folder_name = 'data'\n",
    "\n",
    "folder_path = os.path.join(folder_name)\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.mkdir(folder_path)\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/dnishimoto/python-deep-learning/master/list%20iterators%20and%20generators.ipynb\", f\"{folder_path}/test.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Get the data\n",
    "\n",
    "#### Download the data and process it in order to obtain:\n",
    "\n",
    "* `X_train:` list with reviews for training.\n",
    "* `y_train:` list with labels for training.\n",
    "* `X_test:` list with reviews for testing.\n",
    "* `y_test:` list with labels for testing.\n",
    "\n",
    "`Notes:` Use the target column as `positive`, that way the positive value will be indicated with a value of `1` and negative with a value of `0`. In this case, a split train/test is not necessary because the original data is already separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from numpy import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_filenames(directory: str, separator: str) -> list:\n",
    "    \"\"\"\n",
    "    This function will return all the filenames of the specified directory.\n",
    "\n",
    "    It uses os.walk to walkthrough over the entire directory and get only the files that end with .txt.\n",
    "        \n",
    "    Return\n",
    "    ------------------------------\n",
    "    list_of_filenames: list with filenames\n",
    "    \"\"\"\n",
    "    list_of_filenames = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                list_of_filenames.append(os.path.join(root, file).split(separator)[-1])\n",
    "\n",
    "    return list_of_filenames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get filenames of positive & negative reviews from training directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_directory = \"C:/Users/Fede/Desktop/FOCUS/AnyoneAI/SprintV/Project_006_Sentiment_Analysis/aclImdb/train/pos\"\n",
    "separator = '\\\\'\n",
    "list_of_pos_filenames = get_list_filenames(directory=pos_directory, separator=separator)\n",
    "print(f\"Total count of filenames in train dataset of positives reviews: {len(list_of_pos_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_directory = \"C:/Users/Fede/Desktop/FOCUS/AnyoneAI/SprintV/Project_006_Sentiment_Analysis/aclImdb/train/neg\"\n",
    "separator = '\\\\'\n",
    "list_of_neg_filenames = get_list_filenames(directory=neg_directory, separator=separator)\n",
    "print(f\"Total count of filenames in train dataset of negative reviews: {len(list_of_neg_filenames)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get filenames of positive & negative reviews from test directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_directory_test = \"C:/Users/Fede/Desktop/FOCUS/AnyoneAI/SprintV/Project_006_Sentiment_Analysis/aclImdb/test/pos\"\n",
    "separator = '\\\\'\n",
    "list_of_pos_filenames_test = get_list_filenames(directory=pos_directory_test, separator=separator)\n",
    "print(f\"Total count of filenames in test dataset of positives reviews: {len(list_of_pos_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_directory_test = \"C:/Users/Fede/Desktop/FOCUS/AnyoneAI/SprintV/Project_006_Sentiment_Analysis/aclImdb/test/neg\"\n",
    "separator = '\\\\'\n",
    "list_of_neg_filenames_test = get_list_filenames(directory=neg_directory_test, separator=separator)\n",
    "print(f\"Total count of filenames in test dataset of negative reviews: {len(list_of_neg_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_corpus(list_of_filenames: list, directory: str) -> list:\n",
    "    \"\"\"\n",
    "    Get the content of each file (i.e: the entire review of a moovie).\n",
    "    Each content will be appended to a list as a unique element, despite being strings or integers.\n",
    "        \n",
    "    Return\n",
    "    ------------------------------\n",
    "    list_of_corpus: list \n",
    "    \"\"\"\n",
    "    list_of_corpus = []\n",
    "    for file in list_of_filenames:\n",
    "        try:\n",
    "            with open(f\"{directory}/{file}\", encoding=\"utf8\") as f:\n",
    "                list_of_corpus.append(f.read())\n",
    "            print(f\"File {file} succesfully appended\")\n",
    "        except:\n",
    "            print(f'The file {file} is not in the specified directory')\n",
    "\n",
    "    return list_of_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get corpus of each file (into a list) from training filename lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_positive_corpus = get_list_of_corpus(list_of_filenames=list_of_pos_filenames, directory=pos_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_negative_corpus = get_list_of_corpus(list_of_filenames=list_of_neg_filenames, directory=neg_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get corpus of each file (into a list) from test training lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_positive_corpus_test = get_list_of_corpus(list_of_filenames=list_of_pos_filenames_test, directory=pos_directory_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_negative_corpus_test = get_list_of_corpus(list_of_filenames=list_of_neg_filenames_test, directory=neg_directory_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bring together negative and positive train reviews into one list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in list_of_negative_corpus:\n",
    "    list_of_positive_corpus.append(review)\n",
    "\n",
    "list_of_corpus_final = list_of_positive_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bring together negative and positive test reviews into one list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in list_of_negative_corpus_test:\n",
    "    list_of_positive_corpus_test.append(review)\n",
    "\n",
    "list_of_corpus_final_test = list_of_positive_corpus_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a positive & negative array (full of 1 and 0 values respectively):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_array = np.full(shape=12500,fill_value=1, dtype=np.int64)\n",
    "negative_array = np.full(shape=12500,fill_value=0, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sum up X_train/y_train and X_test/y_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.Series(list_of_corpus_final)\n",
    "y_train =  hstack([positive_array,negative_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.Series(list_of_corpus_final_test)\n",
    "y_test = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Don't change anything in this block, just make it run correctly*\n",
    "\n",
    "We are going to check that you have done it right and for that we are going to see if the dimensions match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(X_train, y_train, X_test, y_test):\n",
    "    if len(X_train) == len(y_train) == len(X_test) == len(y_test) == 25000:\n",
    "        print('Reading Data Success!')\n",
    "    else:\n",
    "        raise ValueError('Dimensions do not match!')\n",
    "\n",
    "check_data(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Normalize the data\n",
    "\n",
    "#### Create the following functions but not here in the notebook, do it in the python script called `text_normalizer.py` and import them into the notebook (this way you can build your own NLP preprocessing library). In fact, the structure of the functions is already written, you must complete them with the code that you consider necessary.\n",
    "\n",
    "#### Respect names and minimal interfaces:\n",
    "\n",
    "* `remove_html_tags(text):` to remove all HTML tags that may be present in text.\n",
    "* `remove_accented_chars(text):` to remove accented characters from text\n",
    "* `expand_contractions(text):` to expand contractions of the type, \"don't\" to \"do not\". The contractions are already defined in the \"contractions.py\" file.\n",
    "* `lemmatize_text(text):` to lemmatize text.\n",
    "* `stem_text(text):` to apply stemming (NLTK's PorterStemmer) on text.\n",
    "* `remove_special_chars(text):` to remove special characters from text.\n",
    "* `remove_special_chars(text, remove_digits=True):` to remove numbers, note that it is the same function to remove special characters with the addition of an argument that enables or disables the removal of numbers.\n",
    "* `remove_stopwords(text, stopwords=stop_words):` to remove stopwords from text.\n",
    "* `remove_extra_new_lines(text):` to remove extra newlines from text.\n",
    "* `remove_extra_whitespace(text):` to remove extra whitespaces from text.\n",
    "\n",
    "If you want to add more features that would be great, for example you could start by removing emojis, using different stemming algorithms, etc. The more functions you have the better, remember that the texts are very varied and the preprocessing depends a lot on the source of our data.\n",
    "\n",
    "To apply each of the functions you created and pre-process the dataset, you must use the `normalize_corpus` function of the `text_normalizer.py` script. In this method each of the functions you wrote is called, in fact you must enable or disable what you consider necessary (`at this point we leave it to your free choice, for example: you can lemmatize or apply stemming or directly not apply any of the two and so on with the rest, but that is your choice`), this function simply groups the previous ones for a more simplified use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Don't change anything in this block, just make it run correctly*\n",
    "\n",
    "We are going to check that the pre-processing does what we need it to do, for this we are going to test the functions with predefined inputs and we are going to see if the outputs match what we are looking for.\n",
    "\n",
    "Note that the functions are not defined in the notebook itself, but rather that they are in a python file and you must import them in order to use them. Same thing with names, you're going to have to name your functions the way they were named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import text_normalizer\n",
    "\n",
    "# Inputs\n",
    "doc_html = \"\"\"\n",
    "<br /><br />But with plague out there and the news being kept a secret,\n",
    "the New Orleans PD starts a dragnet of the city's underworld.\n",
    "\"\"\"\n",
    "doc_accented = \"Héllo, thís is an accented sénténce.\"\n",
    "doc_contractions = \"I can't, because it doesn't work.\"\n",
    "doc_lemma = \"The striped bats are hanging on their feet for best\"\n",
    "doc_stem = \"\"\"\n",
    "Where did he learn to dance like that?\n",
    "His eyes were dancing with humor.\n",
    "She shook her head and danced away.\n",
    "\"\"\"\n",
    "doc_specials = \"hello? there A-Z-R_T(,**), world, welcome to python. this **should? the next line#followed- by@ an#other %million^ %%like $this.\"\n",
    "doc_digits = \"abc123def456ghi789zero0 hello my friend number 10\"\n",
    "doc_stop = \"He is a very good person\"\n",
    "doc_new_lines = \"\"\"we\n",
    "use\n",
    "a\n",
    "lot\n",
    "of\n",
    "lines\"\"\"\n",
    "doc_spaces = \"Hello           my      dear          friend\"\n",
    "\n",
    "# Outputs\n",
    "good_html = \"\"\"\n",
    "But with plague out there and the news being kept a secret,\n",
    "the New Orleans PD starts a dragnet of the city's underworld.\n",
    "\"\"\"\n",
    "good_accented = \"Hello, this is an accented sentence.\"\n",
    "good_contractions = \"I cannot, because it does not work.\"\n",
    "good_lemma = \"the stripe bat be hang on their foot for good\"\n",
    "good_stem = \"where did he learn to danc like that ? hi eye were danc with humor. she shook her head and danc away .\"\n",
    "good_specials = \"hello there AZRT world welcome to python this should the next linefollowed by another million like this\"\n",
    "good_digits = \"abcdefghizero hello my friend number \"\n",
    "good_stop = \"good person\"\n",
    "good_new_lines = \"we use a lot of lines\"\n",
    "good_spaces = \"Hello my dear friend\"\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def check_normalization():\n",
    "    if good_html == text_normalizer.remove_html_tags(doc_html):\n",
    "        print('[1/10] Remove HTML Success!')\n",
    "    else:\n",
    "        raise ValueError('[1/10] Remove HTML Fail!')\n",
    "        \n",
    "    if good_accented == text_normalizer.remove_accented_chars(doc_accented):\n",
    "        print('[2/10] Remove Accented Success!')\n",
    "    else:\n",
    "        raise ValueError('[2/10] Remove Accented Fail!')\n",
    "        \n",
    "    if good_contractions == text_normalizer.expand_contractions(doc_contractions):\n",
    "        print('[3/10] Expand Contractions Success!')\n",
    "    else:\n",
    "        raise ValueError('[3/10] Expand Contractions Fail!')\n",
    "        \n",
    "    if good_lemma == text_normalizer.lemmatize_text(doc_lemma):\n",
    "        print('[4/10] Lemmatization Success!')\n",
    "    else:\n",
    "        raise ValueError('[4/10] Lemmatization Fail!')\n",
    "        \n",
    "    print(text_normalizer.stem_text(doc_stem))\n",
    "    if good_stem == text_normalizer.stem_text(doc_stem):\n",
    "        print('[5/10] Stemming Success!')\n",
    "    else:\n",
    "        raise ValueError('[5/10] Stemming Fail!')\n",
    "        \n",
    "    if good_specials == text_normalizer.remove_special_chars(doc_specials):\n",
    "        print('[6/10] Remove Specials Success!')\n",
    "    else:\n",
    "        raise ValueError('[6/8] Remove Specials Fail!')\n",
    "        \n",
    "    if good_digits == text_normalizer.remove_special_chars(doc_digits, remove_digits=True):\n",
    "        print('[7/10] Remove Digits Success!')\n",
    "    else:\n",
    "        raise ValueError('[7/10] Remove Digits Fail!')\n",
    "        \n",
    "    if good_stop == text_normalizer.remove_stopwords(doc_stop, stopwords=stop_words):\n",
    "        print('[8/10] Remove Stopwords Success!')\n",
    "    else:\n",
    "        raise ValueError('[8/10] Remove Stopwords Fail!')\n",
    "    \n",
    "    if good_new_lines == text_normalizer.remove_extra_new_lines(doc_new_lines):\n",
    "        print('[9/10] Remove New Lines Success!')\n",
    "    else:\n",
    "        raise ValueError('[9/10] Remove New Lines Fail!')\n",
    "        \n",
    "    if good_spaces == text_normalizer.remove_extra_whitespace(doc_spaces):\n",
    "        print('[10/10] Remove Extra Whitespaces Success!')\n",
    "    else:\n",
    "        raise ValueError('[10/10] Remove Extra Whitespaces Fail!')\n",
    "\n",
    "check_normalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Engineering\n",
    "\n",
    "You already have the pr-eprocessed data, now you must vectorize them, because remember that the models only understand numbers. At this stage choose whether you want to vectorize with BoW or with TF-IDF. Later we will train our own embedding but for now we go with a more \"classic\" vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_normalizer import normalize_review\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parallelize normalize texts to **enhance pre-processing time**: (both X_train/X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    X_train_preprocessed = list(executor.map(normalize_review, X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    X_test_preprocessed = list(executor.map(normalize_review, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate vectorizer TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(norm = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit & transform X_train from X_train_preprocessed (which is X_train previously preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proc_vect = vectorizer.fit_transform(X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Same with X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_proc_vect = vectorizer.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling and Performance Evaluation\n",
    "\n",
    "As we said at the beginning, what interests us most in this part is pre-processing. However, we must train a model, so choose a model of your choice (obviously a classification model, given the problem we are facing) and apply everything we learned. Also if you want you can try several models, the more models you use and know better!\n",
    "\n",
    "In addition to training the model we ask you to show:\n",
    "\n",
    "* `Precision`\n",
    "* `Recall`\n",
    "* `F1-Score`\n",
    "* `Classification Report`\n",
    "* `Confusion Matrix`\n",
    "\n",
    "To do this you must complete the `get_performance` function of the `evaluation.py` script.\n",
    "\n",
    "Also, you must complete the `plot_roc` function so that it can show:\n",
    "\n",
    "* `ROC Curve`\n",
    "* `Obtain the ROC-AUC value (later we will do a small minimum performance check with this value)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from evaluation import get_performance, plot_roc\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this case, we are going to use LightGBM as our main classifier. The main reason is that it's easy to enable the GPU as the computing device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbm.LGBMClassifier(device=\"gpu\" ,learning_rate= 0.05, max_depth= -1, num_iterations=150, num_leaves= 100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We fit our function from X_train_proc_vect to y_train. Then we calculate the probability of our predictions, slicing the \"second\" array to grab only those values which represents the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_proc_vect,y_train)\n",
    "\n",
    "lgbm_probs = model.predict_proba(X_test_proc_vect)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We bring up a performance measurement to observe our model's accuracy. In this case, we are going to use **ROC AUC** Score. In addition, we call get_performance, a function that serves us a report of our algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test,lgbm_probs)\n",
    "print(f\"AUC ROC Score: {round(roc_auc,4)}\")\n",
    "get_performance(predictions=lgbm_probs.round(),y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's plot our ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = plot_roc(model=model, y_test=y_test, features=X_test_proc_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Don't change anything in this block, just make it run correctly*\n",
    "\n",
    "Let's check that the `get_performance` function returns the metrics correctly. For that we are going to simulate input/output data of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_basic_metrics():\n",
    "    accuracy, precision, recall, f1_score = evaluation.get_performance(\n",
    "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0], \n",
    "        [1, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "    )\n",
    "    \n",
    "    if (accuracy, precision, recall, f1_score) == (0.6, 0.6, 0.6, 0.6):\n",
    "        print('Success!')\n",
    "    else:\n",
    "        raise ValueError('You must check your get_performance function!')\n",
    "        \n",
    "check_basic_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if your model at least exceeds an ROC-AUC of 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_roc(roc_auc):\n",
    "    if roc_auc > 0.93:\n",
    "        print('Success!')\n",
    "    else:\n",
    "        raise ValueError('Your model is not good enough!')\n",
    "        \n",
    "check_roc(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Feature Engineering with Custom Word Embedding\n",
    "\n",
    "### Tokenize reviews and train your own Word Embedding\n",
    "\n",
    "You are going to have to train your own word embedding, for this we are going to use the __gensim__ library. The only requirement we ask of you is that the $vector\\_size=100$.\n",
    "\n",
    "[Here](https://radimrehurek.com/gensim/models/word2vec.html) you can read Gensim's Word2Vec documentation so you can train your own embedding, using the review data as a corpus.\n",
    "\n",
    "As a previous step to training your word embedding you must tokenize the corpus, this may take a bit depending on the size of the dataset and the tokenizer we use, if you want you can try the NLTK tokenizer called `ToktokTokenizer`, which turns out to be a little faster (we hope that this recommendation does not bias your work, try and use the ones you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from gensim.utils import effective_n_jobs\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "print(f'Number of cores availables: {effective_n_jobs(-1)}')\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Before star training our Word2Vec vectorization, we have to tokenize X_train & X_test (preciously preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = [word_tokenize(token) for token in X_train_preprocessed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokenized = [word_tokenize(token) for token in X_test_preprocessed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate our Word2Vec model. In this case I defined the parameter **sg** as 1, this means that the model will understand each word to predict another context words. Skipgram is better to capture semantic relationships meanwhile studies the context from which the words come. For the sake of the problem we are facing (sentiment analysis), I assume this algorithm will perform better than CBoW (which does the opposite and therefore, will perform better to predict syntactic words in a given context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec(sentences= X_train_tokenized, sg=1, workers=12, vector_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate averaged word vector features\n",
    "\n",
    "Once the embedding has been trained, we must use it. Remember that embedding will convert each word you pass to it into a vector of a given dimension (in our case $vector\\_size=100$). So in order to obtain a vector for each review, you must average the vectors of all the words that are part of the same review.\n",
    "\n",
    "The function must have the following form:\n",
    "* `vectorizer(corpus, model, num_features=100)`\n",
    "\n",
    "\n",
    "Where:\n",
    "* `corpus:` corresponds to the entire dataset, in this way we obtain an average vector for each review, with a single call to the function.\n",
    "* `model:` is your trained model.\n",
    "* `num_features:` the dimension of the output vector of your embedding (remember that in our case we set this value to 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(corpus, model, num_features=100):\n",
    "    \n",
    "    corpus_vectors = []\n",
    "    for token in corpus:\n",
    "        test = np.average([model.wv[word] for word in token if word in model.wv], axis=0)\n",
    "        corpus_vectors.append(test)\n",
    "        \n",
    "    return corpus_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(corpus, model, num_features=100):\n",
    "    \"\"\"\n",
    "    Get the embedding of each sentence. \n",
    "    \n",
    "    It iterates over the sentence and calculate the vector for each word, then, sum that word vector to the final vector composed of 100 dimensions and calculate the average from all vectors.\n",
    "\n",
    "        \n",
    "    Return\n",
    "    ------------------------------\n",
    "    corpus_vectors: list of arrays of 100 dim each one\n",
    "    \"\"\"\n",
    "    \n",
    "    vector_sum = np.zeros(shape=(num_features,))\n",
    "    corpus_vectors = list()\n",
    "\n",
    "    # Loop to average the vectors in a sentence\n",
    "    for sentence in corpus:\n",
    "        counter = 0\n",
    "        for token in sentence:\n",
    "            if token in model.wv:\n",
    "                word_vector = model.wv[token]          \n",
    "                vector_sum = vector_sum + word_vector   \n",
    "                counter += 1\n",
    "        average = vector_sum/counter                \n",
    "        corpus_vectors.append(average) \n",
    "\n",
    "    return corpus_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Don't change anything in this block, just make it run correctly*\n",
    "\n",
    "Let's do a simple check of the embedding that you just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_embedding(model):\n",
    "    vector = model.wv['computer']\n",
    "    if len(vector) == 100:\n",
    "        print(\n",
    "            'Success! Your embedding tells me that \"women\" and \"man\" '\n",
    "            f'are similar with a score of {model.wv.similarity(\"woman\", \"man\")}'\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('You should check your embedding vector size!')\n",
    "        \n",
    "check_embedding(model_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to check the vectorizer, remember that the vectorizer must generate an average vector of all the words present in the same review. So we're going to get two vectors of two words and manually average them, then using those two words we'll simulate a tokenized sentence and see that it matches the manual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vectorizer(model):\n",
    "    vector1 = model.wv['personal']\n",
    "    vector2 = model.wv['computer']\n",
    "    avg = vectorizer([['personal', 'computer']], model)[0]\n",
    "\n",
    "    if np.allclose((vector1 + vector2) / 2, avg):\n",
    "        print('Success!')\n",
    "    else:\n",
    "        raise ValueError('You should check your vectorizer!')\n",
    "        \n",
    "check_vectorizer(model_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Finally train a new model, it can be the same one you used before and compare the results you got using BoW/TF-IDF and Word2Vec.\n",
    "\n",
    "In addition to training the model we ask you to show:\n",
    "\n",
    "* `Accuracy`\n",
    "* `Recall`\n",
    "* `F1-Score`\n",
    "* `Classification Report`\n",
    "* `Confusion Matrix`\n",
    "* `ROC Curve`\n",
    "* `Obtain the ROC-AUC value (later we will do a small minimum performance check with this value)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbm.LGBMClassifier(device=\"gpu\" ,learning_rate= 0.05, max_depth= -1, num_iterations=150, num_leaves= 100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We calculate the average embedding for each sentence from the tokenized X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = vectorizer(corpus=X_train_tokenized, model=model_w2v, num_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_word2vec = vectorizer(corpus=X_test_tokenized, model=model_w2v, num_features=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit the function with our model and predict probabilities to target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_word2vec,y_train)\n",
    "\n",
    "lgbm_probs = model.predict_proba(X_test_word2vec)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate the ROC AUC Score (the higher, the better performance of the algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test,lgbm_probs)\n",
    "print(f\"AUC ROC Score: {round(roc_auc,4)}\")\n",
    "get_performance(predictions=lgbm_probs.round(),y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot CMatrix to observe TP vs TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, lgbm_probs.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = plot_roc(model=model, y_test=y_test, features=X_test_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Don't change anything in this block, just make it run correctly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_roc(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### OPTIONAL:\n",
    "\n",
    "In our case, we train a word embedding from scratch, which is very good at an educational level, but when applying it to a real problem, we need a lot of data (which is not the case with our problem). Therefore, we invite you to investigate and use one of the `pre-trained Word2Vec models`.\n",
    "\n",
    "If you look for the `Pretrained models` section in this [link](https://radimrehurek.com/gensim/models/word2vec.html), you will find information about the models that Gensim owns."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf3fddaf5f16d859b6e8d0eeaf4cfc855ee191cae7b483f6b3cdefa4bf9da992"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
